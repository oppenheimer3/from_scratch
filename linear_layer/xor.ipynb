{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XOR using deep learning\n",
        "in this program i used my implemented linear layer https://github.com/oppenheimer3/from_scratch/tree/master/linear_layer to predict XOR function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB4XiTtZPhDs",
        "outputId": "80dbfea9-5d12-4fef-85a2-82848cc00bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0: the loss:0.7098636627197266\n",
            "epoch 10000: the loss:0.6849256753921509\n",
            "epoch 20000: the loss:0.6146069765090942\n",
            "epoch 30000: the loss:0.4620742201805115\n",
            "epoch 40000: the loss:0.2226513922214508\n",
            "epoch 50000: the loss:0.09898847341537476\n",
            "epoch 60000: the loss:0.05478232353925705\n",
            "epoch 70000: the loss:0.035424526780843735\n",
            "epoch 80000: the loss:0.025248024612665176\n",
            "epoch 90000: the loss:0.019191984087228775\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 0])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.uniform import Uniform\n",
        "import torch.optim as optim\n",
        "class Linear(nn.Module):\n",
        "  def __init__(self, in_features, out_features) -> None:\n",
        "    super().__init__()\n",
        "    self.in_features = torch.tensor(in_features)\n",
        "    self.out_features = torch.tensor(out_features)\n",
        "    self.u = Uniform(-1/torch.sqrt(self.in_features), 1/torch.sqrt(self.in_features))\n",
        "    self.A = nn.Parameter(self.u.sample([self.out_features, self.in_features]))\n",
        "    self.b = nn.Parameter(self.u.sample([self.out_features,]))\n",
        "\n",
        "  def forward(self, x):\n",
        "     self.output = x @ self.A.T + self.b\n",
        "     return self.output\n",
        "X = torch.tensor([[0, 0], [1, 0], [0, 1], [1, 1]], dtype=torch.float32)\n",
        "Y = torch.tensor([0, 1, 1, 0])\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, *args, **kwargs) -> None:\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.linear1 = Linear(2, 4)\n",
        "    self.linear2 = Linear(4, 2)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.relu(x)\n",
        "    return self.linear2(x)\n",
        "\n",
        "model = Model()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
        "for i in range(100000):\n",
        "  loss = criterion(model(X), y)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % 10000 == 0:\n",
        "    print(f'epoch {i}: the loss:{loss.item()}')\n",
        "torch.argmax(nn.Softmax(1)(model(X)), dim=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
